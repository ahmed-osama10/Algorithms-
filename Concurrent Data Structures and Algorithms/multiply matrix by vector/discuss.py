# -*- coding: utf-8 -*-
"""discuss.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qQic1VkvB5i3TKa2SOtlJdT_tUjXZLjN

this is the sequential code for the problem
"""

import numpy as np #This imports the NumPy library and assigns it the alias np. The NumPy library is used for mathematical operations and array manipulation.
from scipy.sparse import csr_matrix #This imports the csr_matrix class from the sparse module of the SciPy library, which is used to create sparse matrices.

def sequential_multiply(matrix, vector): #This defines a function called sequential_multiply that takes a matrix and a vector as input.
    result = np.zeros(matrix.shape[0]) # this creates an array of zeros of length equal to the number of rows in the matrix,the shape[0] attribute returns the number of rows in the matrix.
    if isinstance(matrix, csr_matrix): #This checks if the matrix is of type csr_matrix
        for i in range(matrix.shape[0]): #This loop iterates over the number of rows in the matrix.
            for j in range(matrix.indptr[i], matrix.indptr[i + 1]): #This loop iterates over the non-zero elements of the current row in the sparse matrix
                result[i] += matrix.data[j] * vector[matrix.indices[j]] #This multiplies the value of the current non-zero element in the sparse matrix by the corresponding element of the vector, and adds the result to the current element of the result array.
    else: #if the matrix is not sparse matrix
        for i in range(matrix.shape[0]): #This loop iterates over the number of rows in the matrix.
            result[i] = np.dot(matrix[i], vector) #This performs the dot product between the current row of the matrix and the vector and assigns the result to the current element of the result array.
    return result #This returns the final result array, which is the result of the matrix-vector multiplication.

matrix = csr_matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) #This creates a sparse matrix
vector = np.array([1, 2, 3]) #This creates a vector
print(sequential_multiply(matrix, vector)) #This calls the sequential_multiply function, passing in the matrix and the vector as arguments, and print the result.

"""The time complexity of this code for multiplying a matrix by a vector using a linear array of processors in Python is O(nnz) for sparse matrix case, and O(mn) for dense matrix case, where nnz is the number of non-zero elements in the sparse matrix, m is the number of rows in the matrix and n is the number of columns in the matrix.

For the case of the sparse matrix, the code uses the sparse format CSR, which stores the non-zero elements of the matrix in a 1D array, the column indices of the non-zero elements in another 1D array, and a 1D array of indices that define the start and end of each row of non-zero elements in the first two arrays. So, the code iterates over the non-zero elements in the matrix, so the time complexity is directly proportional to the number of non-zero elements in the matrix, which is O(nnz).

For the case of the dense matrix, the code uses the numpy dot function, which is implemented in C and highly optimized, so it's very fast, and the time complexity is O(mn), where m is the number of rows in the matrix and n is the number of columns in the matrix.

The time complexity of O(n) for a matrix-vector multiplication is not possible as the matrix is a 2D array and in order to multiply the matrix with the vector, we need to go through all the elements in the matrix.

However, there are some ways to optimize the code to make it more efficient, such as:

Using sparse matrices: As I mentioned before, sparse matrices are useful in many areas of mathematics, computer science, and engineering because they can be stored and manipulated more efficiently than dense matrices. The time complexity of performing matrix-vector multiplication using sparse matrices is O(nnz) where nnz is the number of non-zero elements in the sparse matrix.

Using optimized libraries: Using optimized libraries such as NumPy or SciPy that have been optimized for performance. These libraries provide highly optimized implementations of common linear algebra operations such as matrix-vector multiplication.

Using specialized hardware: Using specialized hardware such as Graphics Processing Units (GPUs) can significantly improve the performance of matrix-vector multiplication by taking advantage of the parallel computing capabilities of the GPU.

Using strassen algorithm for matrix multiplication which have time complexity of O(n^log2(7)) which is close to O(n)
"""



"""this is parallel code for the problem """

#This code will divide the matrix into chunks, with each chunk being handled by a separate process. The result is stored in a shared memory list,
#so each process can update its portion of the result without interfering with the other processes.
#The processes are started using the Process class from the multiprocessing module and wait for all of them to finish using join method.

from multiprocessing import Process, Manager #This line imports the Process and Manager classes from the multiprocessing module, which are used to create and manage the parallel processes.
#This line defines a function called multiply that takes in 5 parameters: matrix, vector, result, start, and end. 
#The matrix and vector are the input matrices that need to be multiplied. 
#The result is a shared memory list where the function stores the result of the multiplication. 
#The start and end parameters are used to specify the range of rows in the matrix that the function should multiply.

def multiply(matrix, vector, result, start, end):
    for i in range(start, end): #This line starts a loop that iterates over the rows of the matrix between start and end.
        result[i] = 0 #This line initializes the result for the current row to 0.
        for j in range(len(vector)): # This line starts a nested loop that iterates over the elements of the vector.
            result[i] += matrix[i][j] * vector[j] #This line multiplies the corresponding element of the current row of the matrix with the current element of the vector, and adds it to the current value of the result.

if __name__ == '__main__': #This line is used to check whether the script is being run directly or imported as a module.
    # Example matrix and vector
    matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
    vector = [1, 2, 3]

    # Number of processors
    num_processors = 3

    # Divide the matrix into chunks for each processor
    chunk_size = len(matrix) // num_processors #This line calculates the size of each chunk of the matrix that will be assigned to each process.
    chunks = [(i * chunk_size, (i + 1) * chunk_size) for i in range(num_processors)] # This line creates a list of tuples that represent the starting and ending indices of each chunk of the matrix.

    # Create a shared memory list for the result
    with Manager() as manager: #This line creates a manager object that is used to create the shared memory list for the result.
        result = manager.list([0 for i in range(len(matrix))]) #This line creates a shared memory list for the result and initializes it to all 0s.

        # Create and start the processes
        # This line creates a list of Process objects, one for each chunk of the matrix.
        # Each process runs the multiply function and is passed the appropriate arguments.
        processes = [Process(target=multiply, args=(matrix, vector, result, start, end)) for start, end in chunks]
        for p in processes: #This line starts all the processes created in the previous step.
            p.start()

        # Wait for all processes to finish
        for p in processes:
            p.join()

        # Print the result
        print(result)

"""The overall time complexity of this code is O(n^2) where n is the number of rows in the matrix.

The main computation in this code is the nested loop that starts at line 5. The outer loop iterates n times over the rows of the matrix, and the inner loop iterates n times over the elements of the vector. Therefore, the total number of iterations is n*n.

For each iteration, the code performs a simple multiplication and addition operation, which has a constant time complexity of O(1). Therefore, the total time complexity of the nested loop is O(n^2)

The other parts of the code, such as creating the processes, dividing the matrix into chunks, and waiting for the processes to finish, have a constant time complexity of O(1) or O(n) which is insignificant when compared to the O(n^2) time complexity of the nested loop. Therefore, the overall time complexity of the code is O(n^2).

In addition, this implementation uses parallel computing, so the time complexity will be significantly reduced as the number of processors increases.
"""

from multiprocessing import Process, Manager
import numpy as np

def multiply(matrix, vector, result, start, end):
    result[start:end] = matrix[start:end].dot(vector)

if __name__ == '__main__':
    # Example matrix and vector
    matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
    vector = np.array([1, 2, 3])

    # Number of processors
    num_processors = 3

    # Divide the matrix into chunks for each processor
    chunk_size = len(matrix) // num_processors
    chunks = [(i * chunk_size, (i + 1) * chunk_size) for i in range(num_processors)]

    # Create a shared memory list for the result
    with Manager() as manager:
        result = manager.list(np.zeros(len(matrix)))

        # Create and start the processes
        processes = [Process(target=multiply, args=(matrix, vector, result, start, end)) for start, end in chunks]
        for p in processes:
            p.start()

        # Wait for all processes to finish
        for p in processes:
            p.join()

        # Print the result
        print(result)

"""This code will divide the matrix into chunks, with each chunk being handled by a separate process. Each process will use numpy's dot product method to multiply the chunk of the matrix with the vector, this calculation has a time complexity of O(n) because it performs n multiplications and n additions, which is linear to the size of the input. The result is stored in a shared memory list, so each process can update its portion of the result without interfering with the other processes. The processes are started using the Process class from the multiprocessing module and wait for all of them to finish using join method.
In this implementation, we are using numpy library, which has a built-in function dot() for dot product calculation.
It is worth mentioning that the parallel implementation using multiprocessing library is still valid, but the time complexity will be O(n) for each process.

It is important to note that the time complexity of the matrix-vector multiplication is always O(n^2) or O(n) for the sequential or parallel implementation using dot product method, as it requires iterating over all elements of the matrix and the vector, which is at least linear to the size of the input.

To achieve a time complexity of less than O(n), you would need to use a different algorithm or mathematical approach for the matrix-vector multiplication, such as a fast Fourier transform (FFT) based algorithm. FFT based algorithms can achieve a time complexity of O(n log n) by using complex mathematical operations, such as FFT and inverse FFT, which can reduce the number of operations required to perform the multiplication.

However, implementing such an algorithm would require a significant amount of mathematical knowledge and it's not a straightforward task. Furthermore, it's not always the best approach, as it might not be more efficient than the standard O(n^2) or O(n) algorithms in practice, and it can be hard to implement it in parallel or distributed computing.

So, it's important to note that the time complexity of an algorithm is not the only metric for measuring its performance and efficiency, the complexity of the implementation, the hardware, and the data size are also important factors.
"""